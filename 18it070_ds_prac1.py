# -*- coding: utf-8 -*-
"""18IT070_DS_Prac1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QOMzDqWbPTRlh6RYOPjNQ12TFHKEKKOW
"""

pip install selenium

pip install beautifulsoup4

from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

!apt install chromium-chromedriver

from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)

products=[] #List to store name of the product
prices=[] #List to store price of the product
features=[] #List to store rating of the product

driver.get("https://www.flipkart.com/search?q=hp+pavilion&sid=6bo%2Cb5g&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_6_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_6_na_na_na&as-pos=1&as-type=RECENT&suggestionId=hp+pavilion%7CLaptops&requestId=ed3dbcdc-d229-48d1-aec7-9352e603a989&as-backfill=on")

content = driver.page_source
soup = BeautifulSoup(content)

for a in soup.findAll('a',href=True, attrs={'class':'_1fQZEK'}):
    name=a.find('div',attrs={'class':'_4rR01T'})
    price=a.find('div',attrs={'class':'_30jeq3 _1_WHN1'})
    feature=a.find('div',attrs={'class':'fMghEO'})
    products.append(name.text)
    prices.append(price.text)
    features.append(feature.text)

df = pd.DataFrame({'Product Name':products,'Price':prices , 'Feature':features})
print(df.head())
df.to_csv('products.csv', index=False, encoding='utf-8')